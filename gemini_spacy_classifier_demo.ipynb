{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNDiZSQA9zre"
      },
      "outputs": [],
      "source": [
        "# ===================================================================\n",
        "# CELL 1: SETUP\n",
        "# ===================================================================\n",
        "print(\"⏳ Installing stable library versions...\")\n",
        "# This pins spaCy and its plugins to a specific stable version\n",
        "!pip install \"spacy[transformers,lookups]==3.7.2\" datasets scikit-learn pandas google-generativeai --quiet\n",
        "\n",
        "import os\n",
        "# This restart is required for the new libraries to be loaded correctly.\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# 2. IMPORTS AND DATA PREPARATION\n",
        "# ===================================================================\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from spacy.tokens import DocBin\n",
        "import spacy\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO,\n",
        "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "                    force=True)\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"sepidmnorozy/Finnish_sentiment\")\n",
        "df = pd.DataFrame(dataset['train'])\n",
        "\n",
        "# Map labels and define categories\n",
        "label_map = {1: \"POSITIVE\", 0: \"NEGATIVE\"}\n",
        "df['label_name'] = df['label'].map(label_map)\n",
        "categories = list(df['label_name'].unique())\n",
        "\n",
        "# Split data\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(df['text'], df['label_name'], test_size=0.2, random_state=42, stratify=df['label_name'])\n",
        "\n",
        "# Function to create .spacy files\n",
        "def make_docs(data, labels, categories):\n",
        "    docs = []\n",
        "    nlp = spacy.blank(\"fi\")\n",
        "    for text, label in zip(data, labels):\n",
        "        truncated_text = text[:2500]\n",
        "        doc = nlp.make_doc(truncated_text)\n",
        "        cats = {cat: False for cat in categories}\n",
        "        cats[label] = True\n",
        "        doc.cats = cats\n",
        "        docs.append(doc)\n",
        "    return DocBin(docs=docs)\n",
        "\n",
        "# Create and save the data files\n",
        "train_doc_bin = make_docs(X_train, y_train, categories)\n",
        "train_doc_bin.to_disk(\"train.spacy\")\n",
        "valid_doc_bin = make_docs(X_valid, y_valid, categories)\n",
        "valid_doc_bin.to_disk(\"valid.spacy\")\n",
        "logging.info(\"Data preparation complete.\")"
      ],
      "metadata": {
        "id": "UAGj-bAe-Icx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# 3. DEMO: PROGRAMMATIC LABELING WITH GEMINI\n",
        "# ===================================================================\n",
        "# In this section, we demonstrate how an LLM can be used to label\n",
        "# a sample of the data, and we validate its accuracy.\n",
        "\n",
        "# --- Configure API and select a sample ---\n",
        "try:\n",
        "    genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "    logging.info(\"Gemini API configured successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error configuring Gemini API. Check Colab Secrets. Error: {e}\")\n",
        "\n",
        "n_samples_for_demo = 50\n",
        "demo_df = df.sample(n=n_samples_for_demo, random_state=42)\n",
        "logging.info(f\"Selected {n_samples_for_demo} samples for the Gemini demo.\")\n",
        "\n",
        "# --- API call function with retries and safe sleep time ---\n",
        "def get_gemini_label(text, retries=3):\n",
        "    \"\"\"Uses the Gemini API to classify a single piece of text.\"\"\"\n",
        "    prompt = f\"Analyze the sentiment of the following Finnish text. Classify it as either POSITIVE or NEGATIVE. Return only the single word classification. Text: \\\"{text}\\\" Classification:\"\n",
        "\n",
        "    # Use the fast and efficient Flash model\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "    for i in range(retries):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            label = response.text.strip().upper()\n",
        "            if label in [\"POSITIVE\", \"NEGATIVE\"]:\n",
        "                return label\n",
        "        except Exception as e:\n",
        "            logging.warning(f\"API call failed on attempt {i+1}/{retries}. Error: {e}\")\n",
        "\n",
        "        # Wait a safe amount of time before retrying to avoid rate limits\n",
        "        time.sleep(10)\n",
        "\n",
        "    return \"FAILED\"\n",
        "\n",
        "# --- Label the sample ---\n",
        "gemini_labels = []\n",
        "logging.info(\"Starting Gemini labeling (this will take several minutes)...\")\n",
        "for i, text in enumerate(demo_df['text']):\n",
        "    gemini_labels.append(get_gemini_label(text))\n",
        "    if (i + 1) % 10 == 0:\n",
        "        logging.info(f\"Gemini progress: {i + 1}/{len(demo_df)} texts labeled.\")\n",
        "demo_df['gemini_label'] = gemini_labels\n",
        "logging.info(\"Gemini labeling complete.\")\n",
        "\n",
        "# --- Validate Gemini's accuracy ---\n",
        "valid_predictions = demo_df[demo_df['gemini_label'] != 'FAILED']\n",
        "accuracy = accuracy_score(valid_predictions['label_name'], valid_predictions['gemini_label'])\n",
        "logging.info(f\"Gemini Labeling Accuracy: {accuracy:.2%}\")\n",
        "print(\"\\n--- Gemini Labeling Validation Report ---\")\n",
        "print(classification_report(valid_predictions['label_name'], valid_predictions['gemini_label']))"
      ],
      "metadata": {
        "id": "yI7MalCK-MHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# 3. CREATE CUSTOM CONFIG FILE\n",
        "# ===================================================================\n",
        "config_string = \"\"\"\n",
        "[paths]\n",
        "train = null\n",
        "dev = null\n",
        "[system]\n",
        "gpu_allocator = \"pytorch\"\n",
        "seed = 42\n",
        "[nlp]\n",
        "lang = \"fi\"\n",
        "pipeline = [\"transformer\", \"textcat\"]\n",
        "batch_size = 128\n",
        "[components]\n",
        "[components.transformer]\n",
        "factory = \"transformer\"\n",
        "[components.transformer.model]\n",
        "@architectures = \"spacy-transformers.TransformerModel.v1\"\n",
        "name = \"TurkuNLP/bert-base-finnish-cased-v1\"\n",
        "[components.transformer.model.get_spans]\n",
        "@span_getters = \"spacy-transformers.strided_spans.v1\"\n",
        "window = 128\n",
        "stride = 96\n",
        "[components.textcat]\n",
        "factory = \"textcat\"\n",
        "[components.textcat.model]\n",
        "@architectures = \"spacy.TextCatEnsemble.v2\"\n",
        "[components.textcat.model.linear_model]\n",
        "@architectures = \"spacy.TextCatBOW.v2\"\n",
        "exclusive_classes = true\n",
        "ngram_size = 1\n",
        "no_output_layer = false\n",
        "[corpora]\n",
        "[corpora.dev]\n",
        "@readers = \"spacy.Corpus.v1\"\n",
        "path = ${paths.dev}\n",
        "[corpora.train]\n",
        "@readers = \"spacy.Corpus.v1\"\n",
        "path = ${paths.train}\n",
        "[training]\n",
        "dev_corpus = \"corpora.dev\"\n",
        "train_corpus = \"corpora.train\"\n",
        "seed = ${system.seed}\n",
        "gpu_allocator = ${system.gpu_allocator}\n",
        "dropout = 0.1\n",
        "patience = 1600\n",
        "max_epochs = 0\n",
        "eval_frequency = 200\n",
        "[training.optimizer]\n",
        "@optimizers = \"Adam.v1\"\n",
        "learn_rate = 2e-5\n",
        "# FIX: Reduce batcher size to prevent out-of-memory errors\n",
        "[training.batcher]\n",
        "@batchers = \"spacy.batch_by_padded.v1\"\n",
        "size = 500\n",
        "buffer = 256\n",
        "discard_oversize = true\n",
        "\"\"\"\n",
        "with open(\"config.cfg\", \"w\") as f:\n",
        "    f.write(config_string)\n",
        "\n",
        "logging.info(\"✅ Created custom 'config.cfg' successfully with a smaller batch size.\")"
      ],
      "metadata": {
        "id": "IYBa41hS-M9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# 4. TRAIN THE MODEL\n",
        "# ===================================================================\n",
        "!python -m spacy train config.cfg --output ./training --paths.train ./train.spacy --paths.dev ./valid.spacy --gpu-id 0"
      ],
      "metadata": {
        "id": "U1SByRR6-PZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# 5. EVALUATE THE MODEL\n",
        "# IMPORTANT: After training is complete, restart the session\n",
        "# (Runtime -> Restart session) before running this cell.\n",
        "# ===================================================================\n",
        "import spacy\n",
        "import spacy_transformers\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Reload the validation data\n",
        "dataset = load_dataset(\"sepidmnorozy/Finnish_sentiment\")\n",
        "df = pd.DataFrame(dataset['train'])\n",
        "_, X_valid, _, y_valid = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42, stratify=df['label'])\n",
        "\n",
        "# Load the best model\n",
        "nlp_best = spacy.load(\"training/model-best\")\n",
        "print(\"✅ Best model loaded successfully.\")\n",
        "\n",
        "# Get predictions\n",
        "predicted_labels = []\n",
        "for text in X_valid:\n",
        "    doc = nlp_best(text)\n",
        "    predicted_label = max(doc.cats, key=doc.cats.get)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "label_map = {1: \"POSITIVE\", 0: \"NEGATIVE\"}\n",
        "true_labels = y_valid.map(label_map)\n",
        "\n",
        "# Print final report\n",
        "print(\"\\n--- Final spaCy Model Validation Report ---\")\n",
        "print(classification_report(true_labels, predicted_labels))"
      ],
      "metadata": {
        "id": "wONIjy43dvQr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}